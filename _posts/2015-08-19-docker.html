---
layout: post
title: Docker, OSX and remote Ubuntu!
date: 2015-08-19 02:23:11.000000000 -04:00
categories: []
tags: []
status: publish
type: post
published: true
meta:
  _edit_last: '1'
  _pingme: '1'
  _encloseme: '1'
author:
  login: truth
  email: truthbk@gmail.com
  display_name: truth
  first_name: ''
  last_name: ''
---
<p>It was about time to post something... I've been so lazy, I'm not sure why, but it's been a very long time of no activity. I'm not sure if there's been a lack of productivity, interest, I'm not sure... My best bet is I moved places and I absolutely hated the workspace at the apartment, so I guess if you're not happy with your work environment at home, you just don't work as much off-hours. Anyway, enough with the excuses. Let's talk about something real: <b>docker</b>.</p>
<p>As most of you might know, docker is hot right now. It's nothing new at it's root really, containers (LXC) have been around in linux for like over a decade, and I believe even before that in BSD unices, as jails. They both probably came into fruition as an evolution to the typical Unix <i>chroot</i> segregation. I guess the turning point for containers came as a by-product of virtualization. All of a sudden everybody was, and still is, virtualizing their infrastructure...
But if we look a little closer we realize a huge percentage of all server applications run on linux anyways. So virtualizing the entire VM seems a bit expensive in certain contexts and that's where container sound like a badass idea. Containers do have so security issues, that hypervisors have dialed-in, ie. resource isolation, but they provide an elegant, efficient, flexible solution in many scenarios. Anyway, enough with the container intro. So why docker, and why
this post? </p>
<p><a href="http://www.docker.com">Docker</a> defines itself as an open platform for building, shipping and running distributed applications. It gives programmers, development teams and operations engineers the common toolbox they need to take advantage of the distributed and networked nature of modern applications. What it really does is provide a set of tools that allow you to define the software that each of the containers must include - no more, no less. It also allows us to architect our
application into different microservices, each running in its own container. By defining our applications in this manner we can immediately benefit from the isolation and "packaging", to scale and deploy almost seamlessly, and definitely in a very convenient manner. But also, the added flexibility allows us to spin up fresh environments very quickly, and what's more, take copies of live environments to run on a new endpoint as a developer ecosystem - think about the benefits of that in terms of
speeding up development and improving time-to-bugfix. Ok, so you probably already knew all of that... So what's new? Well basically every tutorial out there, if you run OSX wants you to install virtualbox, and then use boot2docker. That works great and it might be the route for 90% of the people. But what if you have a lightweight rig, a macbook air for instance. Or say you actually have a linux VPS. Or you have access to the <a href="https://cloud.google.com/compute/">Google Cloud Platform</a>,
wouldn't you maybe want to spare your machine the burden of containerization? I did. In my case I run and underutilize an Ubuntu VPS, so I figured it made the perfect box for my containers, and since docker follows a client-server model, it had to be mad easy. It was, here are the steps.</p>
<p>
First you install docker in your OSX machine, the client.
</p>
